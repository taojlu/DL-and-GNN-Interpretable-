# Deep Learning and Graph Neural Network Interpretable papers and codes.

### <a href="#id_1"> Part One: Deep Learning Interpretable Survey </a>
### <a href="#id_2"> Part Two: Deep Learning Interpretable Papers </a>
### <a href="#id_3"> Part Two: Graph Neural Network INterpretable Survey </a>
### <a href="#id_4">   Part Two: Deep Learning Interpretable Papers </a>
### <a href="#id_5"> Part Three: Deep Learning Interpretable Scholars </a>
### <a href="#id_6"> Part Four: Technology Tools </a>
&nbsp;
&nbsp;
&nbsp;
#### <span id="id_1"> Part One: Deep Learning Interpretable Survey

Title | Date | Links |First Author| Code|
:---- |-----:|------:|-----------:|:-----:
A Survey on Explainable Artificial Intelligence (XAI): towards Medical XAI | 2020 | [arXiv](https://arxiv.org/pdf/1907.07374.pdf) | Erico Tjoa | No |
A Survey on Techniques, Applications and Security of Machine Learning Interpretability | 2019 | [计算机研究与发展](https://nesa.zju.edu.cn/download/%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E3%80%81%E5%BA%94%E7%94%A8%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E6%80%A7%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0.pdf) | 纪守领 | No |
Visual Interpretability for Deep Learning: a Survey | 2018 | [arXiv](https://arxiv.org/pdf/1802.00614.pdf) | Quanshi Zhang | No |
Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI) | 2018 | [IEEE Access](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466590) | AMINA ADADI | No |

#### <span id="id_2"> Part Two: Deep Learning Interpretable Papers

Title | Date | Links |First Author| Model |
:---- |-----:|------:|-----------:|:-----:
SAUNet: Shape Attentive U-Net for Interpretable Medical Image Segmentation | 2020 | [MICCAI](https://arxiv.org/pdf/2001.07645.pdf) | Jesse Sun | [U-Net](https://github.com/sunjesse/shape-attentive-unet) |   
Local Interpretable Model-Agnostic Explanations for Classification of Lymph Node Metastases | 2019 | [sensors](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6651753/) | Iam Palatnik de Sousa | --- |   
Uncertainty Modeling and Interpretability In Convolutional Neural Networks for Polyp Segmentation | 2018 | [IEEE International Workshop on Machine Learning For Signal Processing](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8516998) | Kristoffer Wickstrøm | No |  






#### <span id="id_3"> Part Three: Graph Neural Network Interpretable Survey

Title | Date | Links |First Author| Code|
:---- |-----:|------:|-----------:|:-----:
Explainability Methods for Graph Convolutional Neural Networks | 2019 | [CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.pdf) | Phillip E.Pope | No |
Explainability Techniques for Graph Convolutional Networks | 2019 | [arXiv](https://arxiv.org/pdf/1905.13686.pdf)| Federico Baldassarre | [github](https://github.com/baldassarreFe/graph-network-explainability)|


#### <span id="id_4"> Part Four: Graph Neural Network Interpretable Papers

Title | Date | Links |First Author| Code|
:---- |-----:|------:|-----------:|:-----:
Interpretable Neuron Structuring with Graph Spectral Regularization | 2020 | [arXiv](https://arxiv.org/pdf/1810.00424.pdf) | Alexander Tong | [github](https://github.com/KrishnaswamyLab/GraphSpectralRegularization) |    
XGNN: Towards Model-Level Explanations of Graph Neural Networks | 2020 | [KDD](https://arxiv.org/pdf/2006.02587.pdf) | Hao Yuan | No |  
Interpretable and Efficient Heterogeneous Graph Convolutional Network | 2020 | [arXiv](https://arxiv.org/pdf/2005.13183.pdf) | Yaming Yang | [Pytorch](https://github.com/kepsail/ie-HGCN/) |  
Towards Interpretable Sparse Graph Representation Learning with Laplacian Pooling | 2020 | [arXiv](https://arxiv.org/pdf/1905.11577.pdf) | Emmanuel Noutahi | No |
GNNExplainer: Generating Explanations for Graph Neural Networks | 2019 | [NeurIPS](https://arxiv.org/pdf/1903.03894.pdf) | Rex Ying | [github](https://github.com/RexYing/gnn-model-explainer)|  
Factor Graph Neural Network | 2019 | [arXiv](https://arxiv.org/pdf/1906.00554.pdf) | Zhen Zhang | [github](https://github.com/BeautyOfWeb/FactorGraphNeuralNet) |  
Discovering Molecular Functional Groups Using Graph Convolutional Neural Networks | 2019 |[arXiv](https://arxiv.org/pdf/1812.00265.pdf) | Philip E.Pope | No |  
BayesGrad: Explaining Predictions of Graph Convolutional Networks | 2018 | [arXiv](https://arxiv.org/pdf/1807.01985.pdf) | Hirotaka Akita | [github](https://github.com/pfnet-research/bayesgrad)|  

#### <span id="id_5"> Part Five: Deep Learning Interpretable Scholars

#### <span id='id_6'>  Part Six: Technology Tools
1、[Captum](https://github.com/pytorch/captum)  
   &emsp; Captum is a model interpretability and understanding library for PyTorch.  
2、[Convolutional Neural Network Visualizations](https://github.com/utkuozbulak/pytorch-cnn-visualizations)    
   &emsp; This repository contains a number of convolutional neural network visualization techniques implemented in PyTorch.  
   
   
